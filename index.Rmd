---
title: "The house of the rising sun"
author: "Jaco Prins"
date: "Spring 2023"
output: 
  flexdashboard::flex_dashboard:
    # storyboard: true
    orientation: columns
    vertical_layout: fill
    self_contained: false
    theme: 
      version: 4
      bootswatch: minty
      
---
<style>

.storyboard-nav .sbframelist {
    margin: 0 auto;
    width: 94%;
    height: 70px;
    overflow: hidden;
    text-shadow: none;
    margin-bottom: 8px;
}

.storyboard-nav .sbnext, .storyboard-nav .sbprev {
    float: left;
    width: 2%;
    height: 70px;
    font-size: 50px;
}

</style>
```{r}
library(tidyverse)
library(spotifyr)
library(htmltools)
library(compmus)
library(plotly)
library(flexdashboard)
library(ggplot2)
library(plyr) 
library(egg)
library(ggdendro)
library(heatmaply)
library(tidymodels)
library(gghighlight)
library(cowplot)

# get the audio features
house <- get_playlist_audio_features("", "3Bjr19sZK5leO42HHU5Uwo") |>
  mutate(artist.name = map_chr(track.artists, \(x) x |> pluck("name", 1)))

bending <- get_playlist_audio_features("spotify", "4ak7z48oAQXMmytARE84Jp")
base <- get_playlist_audio_features("spotify", "6WtspFzvaGk58QtzHrtuRb")

Rising_Sun <- readRDS(file="data/Rising_Sun.Rda")
```

1. Corpus {.storyboard}
======================================
### Introduction

The house of the rising sun is an old folk song and like most folk songs the exact origins and author are unknown. The oldest published lyrics were written down by Robert Winslow Gordon, an academic collector of folk songs, in 1925. Throughout the last century many different covers of the song have been made with many different styles. Arguably the most well known version is of course the one by The Animals from 1964. Its Iconic arpeggio chords, the haunting vocals and the synth solo. Most people will point at this version of the song as the version of the house of the rising song that they know.\
However, many covers have been made of the song, 120 of which are in the corpus. Ranging from covers that stay very true to, what we will take as the ‘original’ song, the Animals version, all the way to covers that take most people a little time to recognize. But what makes a cover a very different style version of a song, but still recognisable? And is there a way to classify songs as a very similar style version as opposed to a very different one?\
This portfolio tries to answer which features are most important in classifying covers that are very similar to the original and covers that are very different from the original, when splitting the songs on genre. Looking at the differences between all the covers in the large collection, to see whether certain the Spotify generated features or lower level track analysis will show a good way to make a distinction.\
In the end the theory will be tested by training a random forest model on the features that were found to see whether they make a good classification tool to make a good distinction between the similar genres and the genres that differ a lot from the Animals version of the house of the rising sun.

***
```{r image, fig.show = "hold", out.width = "100%", fig.align = "default"}
knitr::include_graphics("figure/download.jpg")
```

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7BY005dacJkbO6EPiOh2wb?utm_source=generator" width="100%" height="140" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


### Explanation of the song
This is the divide of the corpus into the two genre playlists. The divide was based on the :\

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6WtspFzvaGk58QtzHrtuRb?utm_source=generator" width="45%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy" align="left"></iframe>

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/4ak7z48oAQXMmytARE84Jp?utm_source=generator" width="45%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy" align="right"></iframe>

***

The concept of making versions of a song is interesting, as what makes it a cover and what makes it a different song? These covers all lean heavily on the lyrics (although some tracks are fully instrumental) and the motif and chord progression of the song: \
Am  - C   - D   - F   - Am  - E   - Am  - E7\
I   - III - IV  - VI  - I   - V   - I   - V7\
Most of the versions especially the earlier versions are in the key of A minor, so in the explanation this will be used as the key to explain the song other than the intervals.




### Genre distribution

```{r image_grobs, fig.show = "hold", out.width = "50%", fig.align = "default"}
knitr::include_graphics("figure/Base.png")
knitr::include_graphics("figure/Bending.png")
```

***

The first choice to look at is genre. Do the versions that are closest to the original version get categorized in a similar genre? Genres tend to have similar style and build up, so one would think they would be similar.\

For this the corpus got broken up into two playlists: one base genre that adheres to the most appearing genres: rock, folk, country and blues and one genre bending playlist that includes many different genres, from scat jazz to Hip Hop.


2. Visualisations{.storyboard}
======================================
Inputs {.sidebar}
------------------------------------------------------------------
#### House of the Rising Sun
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/3Bjr19sZK5leO42HHU5Uwo?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### Stats on the corpus

```{r}
key <-
Rising_Sun%>%
  ggplot(aes(x=key, fill=as.factor(mode))) +
  ggtitle("Distribution of key signatures and mode")+
  xlab("key signature") +
  ylab("count") +
  geom_histogram(binwidth = 1)+
  labs(fill="Mode: 0 = minor")

key_playlist <- 
  Rising_Sun%>%
  ggplot(aes(x=key, fill=as.factor(playlist_name))) +
  ggtitle("Distribution of key signatures and mode")+
  xlab("key signature") +
  ylab("count") +
  geom_bar()+
  labs(fill="Playlist")

mode_playlist <- 
  Rising_Sun%>%
  ggplot(aes(x=key, fill=as.factor(playlist_name))) +
  ggtitle("Distribution of key signatures and mode")+
  xlab("key signature") +
  ylab("count") +
  geom_bar() +
  labs(fill="Playlist")

plot_grid(key, key_playlist, mode_playlist, ncol = 1)
```

---

The first plot shows that most of the versions uphold the Am key of the original, but there is still some distribution. You can see that as soon as people start playing around with the key they are more likely to change the mode as well.\
The second plot shows that the distribution of the key signatures is fairly equal. The third plot however shows the major mode is used much more frequently in the bending playlist.\
It is fairly easy to change the key of a piece as one can simply modulate all the notes of a piece. However changing the mode of a piece can influence the vibe of the piece, which might be tied into changing the genre.

### Stats but without plot_grid
```{r}
Rising_Sun%>%
  ggplot(aes(x=key, fill=as.factor(mode))) +
  ggtitle("Distribution of key signatures and mode")+
  xlab("key signature") +
  ylab("count") +
  geom_histogram(binwidth = 1)+
  labs(fill="Mode: 0 = minor")

Rising_Sun%>%
  ggplot(aes(x=key, fill=as.factor(playlist_name))) +
  ggtitle("Distribution of key signatures and mode")+
  xlab("key signature") +
  ylab("count") +
  geom_bar()+
  labs(fill="Playlist")

Rising_Sun%>%
  ggplot(aes(x=key, fill=as.factor(playlist_name))) +
  ggtitle("Distribution of key signatures and mode")+
  xlab("key signature") +
  ylab("count") +
  geom_bar() +
  labs(fill="Playlist")
```


### Energy, loudness and time signature

```{r}
analysis <- ggplot(Rising_Sun, aes(x= energy, y=valence, color=as.factor(playlist_name), shape=as.factor(time_signature))) +
  ggtitle("Analysis: Energy - Loudness - Time signature") +
  geom_point()+
  xlim(0,1) + ylim(0,1) +
  xlab("Energy") +
  ylab("Valence") +
  labs(col="Legend", shape="") +
  geom_text(aes(label=ifelse(artist.name == "The Animals",artist.name, ""), point.padding = 0.5,),hjust=0,vjust=0)

ggplotly(analysis)

```

---

This plot shows the correlation between energy, loudness and time signatur The main cloud of datapoints seem to have a similar distribution. Only for a small group of data points you can see that the tracks with the most energy and the highest valence are in 4/4 measure.

### Based on Forest

```{r}
analysis <- ggplot(Rising_Sun, aes(x= instrumentalness, y=energy, color=as.factor(playlist_name))) +
  ggtitle("Analysis: Speechiness - Energy - Instrumentalness") +
  geom_point()+
  xlim(0,1) + ylim(0,1) +
  xlab("Instrumentalness") +
  ylab("Energy") +
  labs(col="Playlist") 
  # gghighlight(artist.name == "The Animals", label_key = artist.name)

ggplotly(analysis)

```

### Energy distribution overall

```{r}
energy <- ggplot(house, aes(x=energy)) +
  ggtitle("Energy distribution over all the songs")+
  xlab("Energy") +
  ylab("Count") +
  geom_histogram(binwidth = 0.1, color="white", fill="aquamarine3") +
  gghighlight(artist.name == "The Animals", label_key = artist.name)

ggplotly(energy)
```

---

This plot shows how the energy throughout the entire corpus.


3. Track level {.storyboard}
================================================
### Introduction
In this chapter we’ll look into the more individual track level to look deeper into the differences of the covers. To the 

### Clustering

```{r}
data_for_clustering <- readRDS(file="data/data_for_clustering.Rda")

data_for_clustering |>
  ggdendrogram() +
  geom_text(data = label(data_for_clustering), aes(x, y, 
            label=label, hjust=0, colour=playlist_name),size=2) +
  coord_flip() +
  scale_y_reverse(expand=c(0.2, 0)) +
  theme(axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank()) +
  labs(title = "Clustering the playlists: Base and Bending") +
  guides(
    colour = guide_legend(
      title = "Playlist"
    ) 
  )

```

***
To get a first understanding of what songs are similar the entire corpus was clustered. For the clustering a hierarchical clustering algorithm was used. The different splits are showcased in the dendrogram. The dendrogram shows a few clusters that are parted into the two genre playlists fairly well. There are two almost perfect Base genre clusters.\
The Animals version is clustered into the middle into the very clean base genre cluster. The songs that it is percieved to most similar to are: Geordie Shore, Lo Mejor De Las Baladas Rock, Eric Burdon ande The Hippie Band. The songs that it is percieved to be most different from are: Sonja Malley and Wuauquikana.



### Sectioning
```{r,fig.width = 15, fig.height= 9}
Sonja <- readRDS(file="data/Sonja.Rda")

Sonja_plot <- 
bind_rows(
  Sonja |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  Sonja |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Sonya O'Malley")+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))

Animals <- readRDS(file="data/The_Animals.Rda")

animals_plot <-
  bind_rows(
  Animals |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  Animals |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "The Animals")+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))

Wuauquikuna <- readRDS(file="data/Wuauquikuna.Rda")

Wuauquikuna_plot <-
  bind_rows(
  Wuauquikuna |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  Wuauquikuna |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Wuauquikuna")+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))

Burdon <- readRDS(file="data/Burdon.Rda")

Burdon_plot <-
  bind_rows(
  Burdon |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  Burdon |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Burdon")+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))

Hippie <- readRDS(file="data/Hippie.Rda")


Hippie_plot <-
  bind_rows(
  Hippie |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  Hippie |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Hippier")+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))

plot_grid(animals_plot, Sonja_plot, Wuauquikuna_plot, Hippie_plot, Burdon_plot, ncol = 3)
```

***

These selfsimilarity matrices show the structures that the piece has when it comes to chroma or timbre features. These songs are the most similar and different within the corpus.\
The Animals version shows a slight chorus-verse structures with a very different bridge in the middle of the song. The Hippie and Burdon versions show a very similar build up and also simulate the melody repeating that the chromagram shows with the very small block pattern.\
The Sonja and Wuauquikuna version also show this melody pattern in the chromagram which suggests they use the same melody (which is true listening to the songs), but show a different timbre seqtioning. Both these versions are instrumental and use piano and panflute respectively.


<!-- ### Chordogram -->
<!-- ```{r} -->

<!-- ``` -->


### Tempogram
```{r,fig.width = 15, fig.height= 9}
animals_plot <- readRDS(file="data/animals_plot_temp.rda")+
  ggtitle("The Animals")

Sonja_plot <- readRDS(file="data/Sonja_plot_temp.rda")+
  ggtitle("Sonya O'Malley")

Wuauquikuna_plot <- readRDS(file="data/Wuauquikuna_plot_temp.rda")+
  ggtitle("Wuauquikuna")

Hippie_plot <- readRDS(file="data/Hippie_plot_temp.rda") +
  ggtitle("The Hippie Band")

Burdon_plot <- readRDS(file="data/Burdon_plot_temp.rda")+
  ggtitle("Eric Burdon")


plot_grid(animals_plot, Sonja_plot, Wuauquikuna_plot, Hippie_plot, Burdon_plot, ncol = 3)
```
<!-- All the tempograms are non-cyclic. -->

***

The Animals tempogram shows a tempo of around 230 BPM, which keeps very steady until just before the end of the song where it slows down. This pattern is also present in the version of the Hippie Band, but the version of Eric Burdon starts at around 200 BPM and speeds ever so slightly throughout the song.\
The versions of Sonya and Wuauquikuna show a slight different pattern. Sonya's piano version was clearly hard to pinpoint due to the lack of a rythm section. Wuauquikuna's version starts out very unclear as this section only contains the panflute, but around 80 seconds a faint clapping appears which is replaced by a strumming guitar that show a clear tempo aroun 200 BPM. 


4. Forest and Conclusion {.storyboard}
=========================================
### Introduction
Now we have found the features that show the difference between the genres and we will train an algorithm to see if these features can correctly make a distinction between the different genres of the covers.

### Forest
This is how we trained it:

***

#### The results
The Forest never got very good as you can see in the numbers:

| Components | Precision |Recall  |
|------------|:---------:|:------:|
| Base       |     0.628 |   0.731|
| Bending    |     0.571 |   0.453|


### Conclusion
In all this portfolio shows that eventhough the covers in the bending genre playlist sound much different to The Animals' version, it is hard to correctly predict them using MIR. 
